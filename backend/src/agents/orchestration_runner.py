#!/usr/bin/env python3
"""
Orchestration Runner - Execute orchestration tasks for AMC-TRADER agent system

This script runs the orchestration agent and performs the requested tasks:
1. Monitor execution status and health of each agent
2. Coordinate communication and data flow
3. Handle error propagation and recovery
4. Log orchestration events and interactions
5. Verify system flow optimization
6. Provide summary with recommendations
"""

import asyncio
import sys
import os
import json
import logging
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any

# Add the agents directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from orchestration_agent import OrchestrationAgent, AgentStatus, MessageType, Message


class OrchestrationRunner:
    """Runner for executing orchestration tasks"""
    
    def __init__(self):
        self.orchestrator = None
        self.start_time = datetime.now()
        self.events_log = []
        self.interactions_log = []
        self.errors_log = []
        self.recommendations = []
        
        # Setup logging
        self.setup_logging()
        self.logger = logging.getLogger("orchestration_runner")
    
    def setup_logging(self):
        """Setup comprehensive logging for orchestration"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # Configure root logger
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / f"orchestration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    async def initialize_orchestration(self):
        """Task 1: Initialize orchestration agent and register available agents"""
        self.logger.info("=== INITIALIZING ORCHESTRATION SYSTEM ===")
        
        try:
            # Create orchestration agent with optimized config
            config = {
                'heartbeat_interval': 15,  # More frequent heartbeats for better monitoring
                'timeout_threshold': 120,  # 2-minute timeout for AMC-TRADER agents
                'max_retries': 3,
                'error_threshold': 5
            }
            
            self.orchestrator = OrchestrationAgent(config)
            self.log_event("orchestrator_initialized", {"config": config})
            
            # Register AMC-TRADER agents based on discovered files
            agents_config = [
                {
                    'name': 'data_validation_agent',
                    'capabilities': ['data_validation', 'data_quality', 'schema_validation'],
                    'dependencies': []
                },
                {
                    'name': 'discovery_algorithm_agent', 
                    'capabilities': ['candidate_discovery', 'scoring', 'filtering'],
                    'dependencies': ['data_validation_agent']
                },
                {
                    'name': 'api_integration_agent',
                    'capabilities': ['external_api', 'data_fetching', 'rate_limiting'],
                    'dependencies': []
                },
                {
                    'name': 'backtesting_agent',
                    'capabilities': ['strategy_testing', 'historical_analysis', 'performance_metrics'],
                    'dependencies': ['discovery_algorithm_agent', 'data_validation_agent']
                },
                {
                    'name': 'caching_performance_agent',
                    'capabilities': ['caching', 'performance_optimization', 'memory_management'],
                    'dependencies': ['api_integration_agent']
                },
                {
                    'name': 'monitoring_alerting_agent',
                    'capabilities': ['system_monitoring', 'alerting', 'health_checks'],
                    'dependencies': []
                },
                {
                    'name': 'management_agent',
                    'capabilities': ['resource_management', 'configuration', 'deployment'],
                    'dependencies': ['monitoring_alerting_agent']
                }
            ]
            
            # Register all agents
            for agent_config in agents_config:
                self.orchestrator.register_agent(
                    agent_config['name'],
                    agent_config['capabilities'],
                    agent_config['dependencies'],
                    self.create_mock_agent_handler(agent_config['name'])
                )
                self.log_event("agent_registered", {
                    "agent": agent_config['name'],
                    "capabilities": agent_config['capabilities'],
                    "dependencies": agent_config['dependencies']
                })
            
            # Define AMC-TRADER specific workflows
            self.define_trading_workflows()
            
            self.logger.info(f"Successfully registered {len(agents_config)} agents")
            return True
            
        except Exception as e:
            self.log_error("orchestrator_initialization_failed", str(e), traceback.format_exc())
            return False
    
    def create_mock_agent_handler(self, agent_name: str):
        """Create mock handler for agent simulation"""
        async def handler(message: Message):
            # Simulate agent processing
            await asyncio.sleep(0.1)  # Simulate processing time
            
            self.log_interaction(agent_name, "message_received", {
                "message_id": message.id,
                "type": message.type.value,
                "sender": message.sender,
                "payload_keys": list(message.payload.keys())
            })
            
            # Simulate different agent behaviors
            if agent_name == "data_validation_agent":
                # Simulate data validation results
                if message.payload.get('action') == 'validate_data':
                    response = Message(
                        id=f"response_{message.id}",
                        type=MessageType.RESPONSE,
                        sender=agent_name,
                        recipient=message.sender,
                        payload={
                            "validation_result": "passed",
                            "data_quality_score": 0.95,
                            "issues_found": 0
                        },
                        correlation_id=message.correlation_id
                    )
                    await self.orchestrator.send_message(response)
            
            elif agent_name == "discovery_algorithm_agent":
                # Simulate candidate discovery
                if message.payload.get('action') == 'discover_candidates':
                    await asyncio.sleep(0.5)  # Simulate longer processing
                    response = Message(
                        id=f"response_{message.id}",
                        type=MessageType.RESPONSE,
                        sender=agent_name,
                        recipient=message.sender,
                        payload={
                            "candidates_found": 15,
                            "strategy": "hybrid_v1",
                            "top_candidate": "VIGL",
                            "processing_time_ms": 500
                        },
                        correlation_id=message.correlation_id
                    )
                    await self.orchestrator.send_message(response)
            
            # Send heartbeat periodically
            if message.type != MessageType.HEARTBEAT:
                heartbeat = Message(
                    id=f"heartbeat_{agent_name}_{datetime.now().timestamp()}",
                    type=MessageType.HEARTBEAT,
                    sender=agent_name,
                    recipient="orchestration_agent",
                    payload={
                        "status": "running",
                        "metrics": {
                            "cpu_usage": 0.15,
                            "memory_usage": 0.25,
                            "last_action": message.payload.get('action', 'unknown')
                        }
                    }
                )
                await self.orchestrator.send_message(heartbeat)
        
        return handler
    
    def define_trading_workflows(self):
        """Define AMC-TRADER specific workflows"""
        # Market discovery workflow
        discovery_workflow = [
            {
                'name': 'data_validation',
                'agent': 'data_validation_agent',
                'action': 'validate_market_data',
                'parameters': {'sources': ['polygon', 'yahoo'], 'timeframe': '1d'},
                'dependencies': []
            },
            {
                'name': 'api_data_fetch',
                'agent': 'api_integration_agent', 
                'action': 'fetch_market_data',
                'parameters': {'symbols': 'all_active', 'depth': 'level2'},
                'dependencies': ['data_validation_agent']
            },
            {
                'name': 'candidate_discovery',
                'agent': 'discovery_algorithm_agent',
                'action': 'discover_candidates',
                'parameters': {'strategy': 'hybrid_v1', 'limit': 50},
                'dependencies': ['api_integration_agent']
            },
            {
                'name': 'cache_optimization',
                'agent': 'caching_performance_agent',
                'action': 'optimize_cache',
                'parameters': {'strategy': 'aggressive'},
                'dependencies': ['discovery_algorithm_agent']
            }
        ]
        
        # Backtesting workflow
        backtesting_workflow = [
            {
                'name': 'historical_data_prep',
                'agent': 'data_validation_agent',
                'action': 'prepare_historical_data',
                'parameters': {'period': '1y', 'resolution': '1h'},
                'dependencies': []
            },
            {
                'name': 'strategy_backtest',
                'agent': 'backtesting_agent',
                'action': 'run_backtest',
                'parameters': {'strategy': 'hybrid_v1', 'capital': 100000},
                'dependencies': ['data_validation_agent']
            },
            {
                'name': 'performance_analysis',
                'agent': 'backtesting_agent',
                'action': 'analyze_performance',
                'parameters': {'metrics': ['sharpe', 'max_drawdown', 'win_rate']},
                'dependencies': ['backtesting_agent']
            }
        ]
        
        self.orchestrator.define_workflow('market_discovery', discovery_workflow)
        self.orchestrator.define_workflow('strategy_backtest', backtesting_workflow)
        
        self.log_event("workflows_defined", {
            "workflows": ['market_discovery', 'strategy_backtest'],
            "total_steps": len(discovery_workflow) + len(backtesting_workflow)
        })
    
    async def monitor_agent_health(self):
        """Task 2: Monitor execution status and health of each agent"""
        self.logger.info("=== MONITORING AGENT HEALTH ===")
        
        try:
            # Start orchestrator background processes
            orchestrator_task = asyncio.create_task(self.orchestrator.start())
            
            # Allow time for initialization
            await asyncio.sleep(2)
            
            # Monitor for 30 seconds
            monitor_duration = 30
            monitor_end = datetime.now() + timedelta(seconds=monitor_duration)
            
            while datetime.now() < monitor_end:
                status = self.orchestrator.get_system_status()
                
                self.log_event("health_check", {
                    "timestamp": status['timestamp'],
                    "total_agents": status['system_metrics']['total_agents'],
                    "running_agents": status['system_metrics']['running_agents'],
                    "error_agents": status['system_metrics']['error_agents'],
                    "message_queue_size": status['message_queue_size']
                })
                
                # Check for unhealthy agents
                for agent_name, agent_info in status['agents'].items():
                    if agent_info['status'] not in ['running', 'idle']:
                        self.log_event("agent_health_issue", {
                            "agent": agent_name,
                            "status": agent_info['status'],
                            "error_count": agent_info['error_count'],
                            "last_heartbeat": agent_info['last_heartbeat']
                        })
                
                await asyncio.sleep(5)
            
            # Stop orchestrator for next phase
            await self.orchestrator.stop()
            
            return True
            
        except Exception as e:
            self.log_error("health_monitoring_failed", str(e), traceback.format_exc())
            return False
    
    async def coordinate_communication(self):
        """Task 3: Coordinate communication and data flow between agents"""
        self.logger.info("=== COORDINATING COMMUNICATION AND DATA FLOW ===")
        
        try:
            # Restart orchestrator
            await self.orchestrator.start()
            await asyncio.sleep(1)
            
            # Start market discovery workflow
            workflow_id = f"market_discovery_{datetime.now().timestamp()}"
            success = await self.orchestrator.start_workflow(
                workflow_id, 
                {'name': 'market_discovery', 'steps': self.orchestrator.workflows['market_discovery']['steps']}
            )
            
            if success:
                self.log_event("workflow_started", {
                    "workflow_id": workflow_id,
                    "workflow_type": "market_discovery",
                    "steps_count": len(self.orchestrator.workflows['market_discovery']['steps'])
                })
            
            # Monitor workflow execution for 20 seconds
            execution_time = 20
            end_time = datetime.now() + timedelta(seconds=execution_time)
            
            while datetime.now() < end_time:
                # Check workflow status
                if workflow_id in self.orchestrator.active_workflows:
                    workflow_state = self.orchestrator.active_workflows[workflow_id]
                    
                    self.log_event("workflow_progress", {
                        "workflow_id": workflow_id,
                        "current_step": workflow_state.get('current_step', 0),
                        "completed_steps": workflow_state.get('completed_steps', []),
                        "status": workflow_state.get('status', 'unknown')
                    })
                
                # Send test messages between agents
                test_message = Message(
                    id=f"test_coordination_{datetime.now().timestamp()}",
                    type=MessageType.COMMAND,
                    sender="orchestration_runner",
                    recipient="data_validation_agent",
                    payload={
                        "action": "validate_data",
                        "data_source": "test_coordination",
                        "priority": "high"
                    }
                )
                await self.orchestrator.send_message(test_message)
                
                await asyncio.sleep(3)
            
            await self.orchestrator.stop()
            return True
            
        except Exception as e:
            self.log_error("communication_coordination_failed", str(e), traceback.format_exc())
            return False
    
    async def handle_error_scenarios(self):
        """Task 4: Handle error propagation and recovery scenarios"""
        self.logger.info("=== HANDLING ERROR PROPAGATION AND RECOVERY ===")
        
        try:
            await self.orchestrator.start()
            await asyncio.sleep(1)
            
            # Test error scenarios
            error_scenarios = [
                {
                    "name": "agent_timeout_simulation",
                    "description": "Simulate agent timeout by stopping heartbeats",
                    "agent": "backtesting_agent"
                },
                {
                    "name": "invalid_message_test",
                    "description": "Send invalid message to test error handling",
                    "agent": "discovery_algorithm_agent"
                },
                {
                    "name": "workflow_step_failure",
                    "description": "Simulate workflow step failure",
                    "agent": "api_integration_agent"
                }
            ]
            
            for scenario in error_scenarios:
                self.log_event("error_scenario_start", {
                    "scenario": scenario["name"],
                    "description": scenario["description"],
                    "target_agent": scenario["agent"]
                })
                
                if scenario["name"] == "invalid_message_test":
                    # Send malformed message
                    invalid_message = Message(
                        id=f"invalid_{datetime.now().timestamp()}",
                        type=MessageType.COMMAND,
                        sender="orchestration_runner",
                        recipient=scenario["agent"],
                        payload={
                            "invalid_action": None,
                            "malformed_data": {"unclosed": {"dict": "test"}}
                        }
                    )
                    await self.orchestrator.send_message(invalid_message)
                
                elif scenario["name"] == "workflow_step_failure":
                    # Start workflow that will fail
                    fail_workflow = [
                        {
                            'name': 'failing_step',
                            'agent': scenario["agent"],
                            'action': 'nonexistent_action',
                            'parameters': {'will_fail': True},
                            'dependencies': []
                        }
                    ]
                    
                    fail_workflow_id = f"fail_test_{datetime.now().timestamp()}"
                    await self.orchestrator.start_workflow(
                        fail_workflow_id,
                        {'name': 'failure_test', 'steps': fail_workflow}
                    )
                
                # Monitor for recovery
                await asyncio.sleep(8)
                
                # Check system status after error
                status = self.orchestrator.get_system_status()
                self.log_event("error_scenario_result", {
                    "scenario": scenario["name"],
                    "system_status": status['system_metrics'],
                    "agent_statuses": {name: info['status'] for name, info in status['agents'].items()}
                })
            
            await self.orchestrator.stop()
            return True
            
        except Exception as e:
            self.log_error("error_handling_failed", str(e), traceback.format_exc())
            return False
    
    async def verify_system_optimization(self):
        """Task 5: Verify system flow optimization"""
        self.logger.info("=== VERIFYING SYSTEM FLOW OPTIMIZATION ===")
        
        try:
            await self.orchestrator.start()
            await asyncio.sleep(1)
            
            # Performance baseline test
            baseline_start = datetime.now()
            
            # Send multiple messages to test throughput
            message_count = 50
            for i in range(message_count):
                test_message = Message(
                    id=f"perf_test_{i}_{datetime.now().timestamp()}",
                    type=MessageType.COMMAND,
                    sender="orchestration_runner",
                    recipient=f"{'data_validation_agent' if i % 2 == 0 else 'discovery_algorithm_agent'}",
                    payload={
                        "action": "performance_test",
                        "test_id": i,
                        "batch_size": message_count
                    },
                    priority=3 if i < 10 else 1  # First 10 messages high priority
                )
                await self.orchestrator.send_message(test_message)
            
            # Wait for processing
            await asyncio.sleep(10)
            baseline_end = datetime.now()
            baseline_duration = (baseline_end - baseline_start).total_seconds()
            
            # Get final system status
            final_status = self.orchestrator.get_system_status()
            
            # Calculate optimization metrics
            optimization_metrics = {
                "message_throughput": message_count / baseline_duration,
                "average_queue_size": final_status['message_queue_size'],
                "agent_response_health": {
                    name: {
                        "status": info['status'],
                        "error_rate": info['error_count'] / max(1, len(self.interactions_log))
                    }
                    for name, info in final_status['agents'].items()
                },
                "workflow_efficiency": len(self.orchestrator.active_workflows),
                "total_processing_time": baseline_duration
            }
            
            self.log_event("optimization_metrics", optimization_metrics)
            
            # Generate optimization recommendations
            if optimization_metrics["message_throughput"] < 10:
                self.recommendations.append({
                    "type": "performance",
                    "priority": "medium",
                    "description": "Message throughput is below optimal. Consider increasing worker threads.",
                    "suggested_action": "Increase OrchestrationAgent executor max_workers"
                })
            
            if optimization_metrics["average_queue_size"] > 5:
                self.recommendations.append({
                    "type": "performance", 
                    "priority": "high",
                    "description": "Message queue backlog detected. System may be overwhelmed.",
                    "suggested_action": "Implement message batching or increase processing capacity"
                })
            
            error_agents = [name for name, info in optimization_metrics["agent_response_health"].items() 
                          if info["error_rate"] > 0.1]
            
            if error_agents:
                self.recommendations.append({
                    "type": "reliability",
                    "priority": "high", 
                    "description": f"High error rates detected in agents: {', '.join(error_agents)}",
                    "suggested_action": "Review agent implementations and add better error handling"
                })
            
            await self.orchestrator.stop()
            return True
            
        except Exception as e:
            self.log_error("optimization_verification_failed", str(e), traceback.format_exc())
            return False
    
    def generate_summary_report(self):
        """Task 6: Generate orchestration summary with recommendations"""
        self.logger.info("=== GENERATING ORCHESTRATION SUMMARY REPORT ===")
        
        end_time = datetime.now()
        total_duration = (end_time - self.start_time).total_seconds()
        
        summary_report = {
            "orchestration_session": {
                "start_time": self.start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "total_duration_seconds": total_duration,
                "session_id": f"orchestration_{self.start_time.strftime('%Y%m%d_%H%M%S')}"
            },
            "system_overview": {
                "total_agents_registered": len([e for e in self.events_log if e.get('event_type') == 'agent_registered']),
                "workflows_defined": len([e for e in self.events_log if e.get('event_type') == 'workflows_defined']),
                "total_events_logged": len(self.events_log),
                "total_interactions": len(self.interactions_log),
                "total_errors": len(self.errors_log)
            },
            "agent_performance": {
                "most_active_agents": self.get_most_active_agents(),
                "error_prone_agents": self.get_error_prone_agents(),
                "communication_patterns": self.analyze_communication_patterns()
            },
            "workflow_execution": {
                "workflows_started": len([e for e in self.events_log if e.get('event_type') == 'workflow_started']),
                "workflow_success_rate": self.calculate_workflow_success_rate(),
                "average_workflow_duration": self.calculate_avg_workflow_duration()
            },
            "error_handling": {
                "error_scenarios_tested": len([e for e in self.events_log if e.get('event_type') == 'error_scenario_start']),
                "recovery_success_rate": self.calculate_recovery_success_rate(),
                "critical_errors": [e for e in self.errors_log if e.get('severity') == 'critical']
            },
            "optimization_findings": {
                "performance_bottlenecks": self.identify_bottlenecks(),
                "resource_utilization": self.analyze_resource_usage(),
                "scalability_assessment": self.assess_scalability()
            },
            "recommendations": self.recommendations,
            "next_actions": self.generate_next_actions()
        }
        
        # Save detailed report
        report_path = Path("logs") / f"orchestration_report_{self.start_time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w') as f:
            json.dump(summary_report, f, indent=2, default=str)
        
        self.logger.info(f"Orchestration report saved to: {report_path}")
        return summary_report
    
    def log_event(self, event_type: str, data: Dict[str, Any]):
        """Log orchestration event"""
        event = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "data": data
        }
        self.events_log.append(event)
        self.logger.info(f"EVENT: {event_type} - {json.dumps(data, default=str)}")
    
    def log_interaction(self, agent: str, interaction_type: str, data: Dict[str, Any]):
        """Log agent interaction"""
        interaction = {
            "timestamp": datetime.now().isoformat(),
            "agent": agent,
            "interaction_type": interaction_type,
            "data": data
        }
        self.interactions_log.append(interaction)
        self.logger.debug(f"INTERACTION: {agent} - {interaction_type}")
    
    def log_error(self, error_type: str, message: str, traceback_info: str, severity: str = "error"):
        """Log orchestration error"""
        error = {
            "timestamp": datetime.now().isoformat(),
            "error_type": error_type,
            "message": message,
            "traceback": traceback_info,
            "severity": severity
        }
        self.errors_log.append(error)
        self.logger.error(f"ERROR: {error_type} - {message}")
    
    # Analysis helper methods
    def get_most_active_agents(self) -> List[Dict[str, Any]]:
        agent_activity = {}
        for interaction in self.interactions_log:
            agent = interaction['agent']
            agent_activity[agent] = agent_activity.get(agent, 0) + 1
        
        return sorted([
            {"agent": agent, "interactions": count} 
            for agent, count in agent_activity.items()
        ], key=lambda x: x['interactions'], reverse=True)[:5]
    
    def get_error_prone_agents(self) -> List[str]:
        agent_errors = {}
        for error in self.errors_log:
            if 'agent' in error.get('data', {}):
                agent = error['data']['agent']
                agent_errors[agent] = agent_errors.get(agent, 0) + 1
        
        return [agent for agent, count in agent_errors.items() if count > 2]
    
    def analyze_communication_patterns(self) -> Dict[str, Any]:
        return {
            "total_messages": len(self.interactions_log),
            "message_types": list(set([i.get('interaction_type') for i in self.interactions_log])),
            "peak_activity_periods": "Analysis not implemented in demo"
        }
    
    def calculate_workflow_success_rate(self) -> float:
        started = len([e for e in self.events_log if e.get('event_type') == 'workflow_started'])
        failed = len([e for e in self.events_log if 'workflow' in e.get('event_type', '') and 'fail' in e.get('event_type', '')])
        return (started - failed) / max(1, started) if started > 0 else 0.0
    
    def calculate_avg_workflow_duration(self) -> str:
        return "Analysis not implemented in demo - would require workflow completion tracking"
    
    def calculate_recovery_success_rate(self) -> float:
        scenarios = len([e for e in self.events_log if e.get('event_type') == 'error_scenario_start'])
        return 0.8 if scenarios > 0 else 0.0  # Demo value
    
    def identify_bottlenecks(self) -> List[str]:
        bottlenecks = []
        if len(self.interactions_log) > 100:
            bottlenecks.append("High message volume - consider batching")
        if len(self.errors_log) > 5:
            bottlenecks.append("Error rate threshold exceeded")
        return bottlenecks
    
    def analyze_resource_usage(self) -> Dict[str, str]:
        return {
            "memory_efficiency": "Good - within expected ranges",
            "cpu_utilization": "Moderate - could optimize message processing",
            "network_usage": "Low - mostly local agent communication"
        }
    
    def assess_scalability(self) -> Dict[str, Any]:
        return {
            "current_capacity": "Supports 7 agents effectively",
            "scaling_recommendations": ["Add message batching", "Implement agent pooling"],
            "bottleneck_points": ["Message queue processing", "Error handling overhead"]
        }
    
    def generate_next_actions(self) -> List[Dict[str, str]]:
        actions = [
            {
                "priority": "high",
                "action": "Implement real agent handlers instead of mock handlers",
                "timeline": "Next development cycle"
            },
            {
                "priority": "medium", 
                "action": "Add persistent logging to database",
                "timeline": "Within 2 weeks"
            },
            {
                "priority": "medium",
                "action": "Create orchestration dashboard for real-time monitoring",
                "timeline": "Future enhancement"
            }
        ]
        
        if len(self.errors_log) > 3:
            actions.insert(0, {
                "priority": "critical",
                "action": "Address error handling gaps identified during testing",
                "timeline": "Immediate"
            })
        
        return actions


async def main():
    """Main orchestration execution"""
    runner = OrchestrationRunner()
    
    print("üéØ Starting AMC-TRADER Orchestration Agent System")
    print("=" * 60)
    
    try:
        # Execute all orchestration tasks
        tasks = [
            ("Initialize Orchestration", runner.initialize_orchestration),
            ("Monitor Agent Health", runner.monitor_agent_health),
            ("Coordinate Communication", runner.coordinate_communication),
            ("Handle Error Scenarios", runner.handle_error_scenarios),
            ("Verify System Optimization", runner.verify_system_optimization)
        ]
        
        for task_name, task_func in tasks:
            print(f"\nüîÑ Executing: {task_name}")
            success = await task_func()
            status = "‚úÖ SUCCESS" if success else "‚ùå FAILED"
            print(f"   {status}: {task_name}")
        
        # Generate final report
        print(f"\nüìä Generating Summary Report")
        report = runner.generate_summary_report()
        
        print("\n" + "=" * 60)
        print("üéØ ORCHESTRATION COMPLETE")
        print(f"üìà Total Events: {len(runner.events_log)}")
        print(f"ü§ù Total Interactions: {len(runner.interactions_log)}")  
        print(f"‚ö†Ô∏è  Total Errors: {len(runner.errors_log)}")
        print(f"üí° Recommendations: {len(runner.recommendations)}")
        print(f"‚è±Ô∏è  Duration: {report['orchestration_session']['total_duration_seconds']:.1f}s")
        
        if runner.recommendations:
            print(f"\nüîç Key Recommendations:")
            for rec in runner.recommendations[:3]:
                print(f"   ‚Ä¢ [{rec['priority'].upper()}] {rec['description']}")
        
        return report
        
    except Exception as e:
        runner.log_error("orchestration_execution_failed", str(e), traceback.format_exc(), "critical")
        print(f"‚ùå CRITICAL ERROR: Orchestration failed - {e}")
        return None


if __name__ == "__main__":
    # Run orchestration
    report = asyncio.run(main())
    
    if report:
        print(f"\n‚úÖ Orchestration completed successfully!")
        print(f"üìÑ Detailed report available in logs/")
    else:
        print(f"\n‚ùå Orchestration failed!")
        sys.exit(1)